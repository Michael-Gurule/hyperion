# HYPERION Configuration File

# Environment Parameters
environment:
  num_agents: 5
  max_steps: 500
  arena_size: 10000.0  # meters
  
  # Target Configuration
  target_speed: 1700.0  # m/s (Mach 5 at sea level)
  
  # Agent Capabilities
  agent_max_speed: 300.0  # m/s
  agent_max_accel: 50.0  # m/s^2
  agent_max_turn_rate: 0.785  # rad/s (45 deg/s)
  
  # Detection and Communication
  detection_range: 2000.0  # meters
  intercept_range: 50.0  # meters
  communication_range: 1500.0  # meters
  
  # Fuel System
  initial_fuel: 1.0
  fuel_consumption_rate: 0.001  # per second at full thrust
  
  # Physics
  dt: 0.1  # timestep in seconds

# Training Parameters
training:
  # RLlib Algorithm
  algorithm: "PPO"  # or "MAPPO", "QMIX"
  
  # PPO Hyperparameters
  ppo:
    lr: 0.0003
    gamma: 0.99
    lambda_gae: 0.95
    clip_param: 0.2
    vf_clip_param: 10.0
    entropy_coeff: 0.01
    num_sgd_iter: 10
    sgd_minibatch_size: 128
    train_batch_size: 4000
  
  # Multi-Agent Settings
  multi_agent:
    policy_mapping: "shared"  # or "independent"
    share_observations: false
    
  # Training Configuration
  num_workers: 4
  num_gpus: 1
  num_envs_per_worker: 1
  rollout_fragment_length: 200
  
  # Checkpointing
  checkpoint_freq: 10
  checkpoint_at_end: true
  keep_checkpoints_num: 5

# Evaluation Parameters
evaluation:
  episodes: 100
  metrics:
    - interception_rate
    - mean_episode_reward
    - mean_fuel_efficiency
    - mean_time_to_intercept
    - collision_rate
  
# Curriculum Learning
curriculum:
  enabled: true
  stages:
    - name: "basic"
      target_speed: 500.0  # Subsonic
      num_agents: 3
      duration_episodes: 1000
    
    - name: "intermediate"
      target_speed: 1000.0  # Supersonic
      num_agents: 5
      duration_episodes: 2000
    
    - name: "advanced"
      target_speed: 1700.0  # Hypersonic
      num_agents: 5
      duration_episodes: 5000

# Adversarial Testing
adversarial:
  enabled: true  # Enable for improved robustness
  evasive_maneuvers: true
  evasion_probability: 0.3
  jink_frequency: 0.5  # Hz
  jink_magnitude: 500.0  # m/s^2
  jamming_enabled: true
  jamming_probability: 0.1
  jamming_duration: 2.0  # seconds
  communication_failure_rate: 0.05

# Scaled Training (50-100+ agents)
scaled_training:
  # Environment
  num_agents: 50
  arena_size: 20000.0
  max_observed_neighbors: 10

  # Algorithm
  algorithm: "MAPPO"  # "MAPPO", "PPO", "GNN_PPO"
  use_gnn: true
  gnn_layers: 3
  gnn_hidden_dim: 128

  # MAPPO settings
  use_centralized_critic: true
  share_actor: true

  # Training
  total_timesteps: 5000000
  rollout_length: 2048
  learning_rate: 0.0003
  num_epochs: 10
  minibatch_size: 256

  # Curriculum
  use_curriculum: true
  curriculum_stages: 4
  advancement_threshold: 0.7

  # Checkpointing
  checkpoint_freq: 50
  checkpoint_dir: "./checkpoints/scaled"

# Scaled Curriculum (for 50-100 agent training)
scaled_curriculum:
  stages:
    - name: "basic"
      num_agents: 10
      target_speed: 500.0
      adversarial_enabled: false
      arena_size: 10000.0

    - name: "intermediate"
      num_agents: 25
      target_speed: 1000.0
      adversarial_enabled: false
      arena_size: 15000.0

    - name: "advanced"
      num_agents: 50
      target_speed: 1500.0
      adversarial_enabled: true
      arena_size: 20000.0

    - name: "expert"
      num_agents: 50
      target_speed: 1700.0
      adversarial_enabled: true
      adversarial_probability: 0.5
      arena_size: 20000.0

# GNN Communication Settings
gnn:
  embed_dim: 64
  hidden_dim: 128
  num_layers: 3
  heads: 4
  dropout: 0.1
  num_roles: 4  # scout, tracker, interceptor, support

# Visualization
visualization:
  render_mode: null  # "human" or "rgb_array"
  save_animations: false
  animation_fps: 10

# Logging and Experiment Tracking
logging:
  log_dir: "./logs"
  log_level: "INFO"

  # TensorBoard
  tensorboard: true
  tensorboard_dir: "./logs/tensorboard"

  # Weights & Biases (wandb)
  wandb: false  # Enable for cloud experiment tracking
  wandb_project: "hyperion"
  wandb_entity: null  # Your W&B username or team name

  # MLflow
  mlflow: false  # Enable for MLflow tracking
  mlflow_tracking_uri: null  # e.g., "http://localhost:5000" or "file:./mlruns"
  mlflow_experiment_name: "hyperion"

# Model Registry
registry:
  path: "./checkpoints/registry.json"
  auto_register: true  # Automatically register checkpoints